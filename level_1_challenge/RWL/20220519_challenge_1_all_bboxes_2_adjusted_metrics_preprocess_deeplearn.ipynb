{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44e516e8-c67d-4f27-8353-7f749f2eed0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Level 1: Local Frog Discovery Tool benchmark notebook\n",
    "\n",
    "## Challenge Level 1 Overview\n",
    "\n",
    "\n",
    "Welcome to the 2022 EY Data Science Challenge! This is the first challenge aimed at beginner/intermediate participants that have little to no experience in data science and programming. For more experienced participants, we recommend undertaking challenge level 2 outlined [here](Model_Level_2.ipynb). If you choose to undertake the first level of the challenge, you will be developing a species distribution model (SDM) for one Australian frog species using only variables from the TerraClimate dataset. A species distribution model is a specific type of machine learning model that aims to predict the distribution of a biological species across geographic space and time. Such models have become increasingly important in conservation efforts globally to better understand and map the habitats of species of interest, particularly threatened or endangered species. \n",
    "\n",
    "The frog species identified for this challenge is Litoria fallax, the eastern dwarf tree frog pictured below. In addition to assisting our understanding of this specific frog species, a successful frog SDM will have broader implications in quantifying biodiversity. This is because frogs are incredibly sensitive to environmental changes, so any changes in their species distribution may indicate an underlying change to biodiversity in the area. \n",
    "\n",
    "<center>\n",
    "<img src=\"pictures/Litoria_fallax.jpg\" width=\"500\" height=\"340\">\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "**Challenge aim:** to develop a species distribution model for litoria fallax across Australia using weather data from the TerraClimate dataset.\n",
    "\n",
    "| Challenge | Locations                     | Spatial Res        | Species          | Satellite Data                                                |\n",
    "|-----------|-------------------------------|--------------------|------------------|---------------------------------------------------------------|\n",
    "|***1***    | Australia                     | Coarse (4km)  | 1 species  | TerraClimate                                                  |\n",
    "|2     | Australia, Costa Rica,<br>South Africa | Fine (10m)   | 15 species     | TerraClimate, Sentinel-2,<br>Land cover, water extent, elevation |\n",
    "\n",
    "In this notebook, we will demonstrate a basic model workflow that can act as a starting point for the challenge. As specified in the first row of the table above, we will restrict this model to regions in Australia at coarse resolution (4kmx4km), predicting one species against the rest of the 5 specified Australian species using only [TerraClimate](https://planetarycomputer.microsoft.com/dataset/terraclimate) predictor variables. In this demonstation, we will be using four features from the TerraClimate dataset, the maximum monthly temperature, the minimum monthly temperature, the mean monthly precipitation, and the mean soil moisture, and will train a logistic regression model with these data. The TerraClimate data is sampled at a monthly temporal resolution, so metrics are calculated over the time dimension to simplify the features. We restrict this analysis to a five year window from the start of 2015 to the end of 2019, and will make the assumption that frog occurrences within that time period are representative of the entire time period (i.e. the frogs take longer than 5 years to move). \n",
    "\n",
    "\n",
    "Most of the functions present in this notebook were adapted from the following notebooks:\n",
    "- [Training Dataset Summary](../supplementary_notebooks/dataset_summary.ipynb)\n",
    "- [TerraClimate/Weather](../supplementary_notebooks/TerraClimate.ipynb)\n",
    "\n",
    "Again, it must be noted that this notebook is just a starting point. We make plenty of assumptions in this notebook that you may not think are best for solving the challenge effectively. You are encouraged to modify these functions, to rewrite them completely, or to try a different approach entirely.\n",
    "\n",
    "\n",
    "## Load in dependencies\n",
    "\n",
    "To run this demonstration notebook, you will need to have the following packages imported below installed. This may take a while. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5652ce4c-c75d-4484-a43a-31ffcf7a2b97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Supress Warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Geospatial\n",
    "import contextily as cx\n",
    "import xarray as xr\n",
    "import zarr # Not referenced, but required for xarray\n",
    "\n",
    "# Import Planetary Computer tools\n",
    "import fsspec\n",
    "import pystac\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import zipfile\n",
    "from itertools import cycle\n",
    "\n",
    "# Path to data folder with provided material\n",
    "data_path = '..//../'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ef421-3dea-4894-a605-d1695657335b",
   "metadata": {},
   "source": [
    "## Response Variable\n",
    "\n",
    "Before we can build our model, we need to load in the frog occurrences data and generate our response variable. To do this, we first need to unzip the training data and store it on our machine. Then we can write a function that abstracts the loading process, with the option of providing a bounding box to only take those occurrences within a region of interest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf305264-0afd-40c3-a9b1-3b782593ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(data_path+'training_data/'):\n",
    "    os.mkdir(data_path+'training_data/')\n",
    "    with zipfile.ZipFile(data_path+'GBIF_training_data.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_path+'training_data/')\n",
    "        \n",
    "def filter_bbox(frogs, bbox):\n",
    "    frogs = frogs[lambda x: \n",
    "        (x.decimalLongitude >= bbox[0]) &\n",
    "        (x.decimalLatitude >= bbox[1]) &\n",
    "        (x.decimalLongitude <= bbox[2]) &\n",
    "        (x.decimalLatitude <= bbox[3])\n",
    "    ]\n",
    "    return frogs\n",
    "\n",
    "def get_frogs(file, year_range=None, bbox=None):\n",
    "    \"\"\"Returns the dataframe of all frog occurrences for the bounding box specified.\"\"\"\n",
    "    columns = [\n",
    "        'gbifID','eventDate','country','continent','stateProvince',\n",
    "        'decimalLatitude','decimalLongitude','species'\n",
    "    ]\n",
    "    country_names = {\n",
    "        'AU':'Australia', 'CR':'Costa Rica', 'ZA':'South Africa','MX':'Mexico','HN':'Honduras',\n",
    "        'MZ':'Mozambique','BW':'Botswana','MW':'Malawi','CO':'Colombia','PA':'Panama','NI':'Nicaragua',\n",
    "        'BZ':'Belize','ZW':'Zimbabwe','SZ':'Eswatini','ZM':'Zambia','GT':'Guatemala','LS':'Lesotho',\n",
    "        'SV':'El Salvador', 'AO':'Angola', np.nan:'unknown or invalid'\n",
    "    }\n",
    "    continent_names = {\n",
    "        'AU':'Australia', 'CR':'Central America', 'ZA':'Africa','MX':'Central America','HN':'Central America',\n",
    "        'MZ':'Africa','BW':'Africa','MW':'Africa','CO':'Central America','PA':'Central America',\n",
    "        'NI':'Central America','BZ':'Central America','ZW':'Africa','SZ':'Africa','ZM':'Africa',\n",
    "        'GT':'Central America','LS':'Africa','SV':'Central America','AO':'Africa', np.nan:'unknown or invalid' \n",
    "    }\n",
    "    frogs = (\n",
    "        pd.read_csv(data_path+'training_data/occurrence.txt', sep='\\t', parse_dates=['eventDate'])\n",
    "        .assign(\n",
    "            country =  lambda x: x.countryCode.map(country_names),\n",
    "            continent =  lambda x: x.countryCode.map(continent_names),\n",
    "            species = lambda x: x.species.str.title()\n",
    "        )\n",
    "        [columns]\n",
    "    )\n",
    "    if year_range is not None:\n",
    "        frogs = frogs[lambda x: \n",
    "            (x.eventDate.dt.year >= year_range[0]) & \n",
    "            (x.eventDate.dt.year <= year_range[1])\n",
    "        ]\n",
    "    if bbox is not None:\n",
    "        frogs = filter_bbox(frogs, bbox)\n",
    "    return frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47010498-24fb-42b1-8ccc-3f7f89235c59",
   "metadata": {},
   "source": [
    "### Sub-sampling\n",
    "\n",
    "For this demonstration, we will constrain our search to frogs in the Greater Sydney area found between the start of 2015 to the end of 2019. This gives a varied landscape of bushland, plains, rivers, and urban areas. This is done by providing `year_range` and `bbox` parameters to the get_frogs function we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c6b93-39bd-4032-b601-56bb8b7cbf92",
   "metadata": {},
   "source": [
    "#### Spatial sampling\n",
    "\n",
    "While we have restricted our analysis to Greater Sydney for this demonstration,  you are encouraged to explore different areas to assist in creating a SDM that is representative of the habitat of litoria fallax. You could even use the entire training set, but keep in mind that loading in large areas may be quite computationally expensive. We recommend loading data in chunks that are a similar size to the bounding box we defined above.\n",
    "\n",
    "#### Temporal sampling\n",
    "\n",
    "Another area that may assist you in developing your SDM is the time dimension of the data. Each occurrence has an \"eventDate\" attribute, and the terraclimate data is taken monthly. You may want to consider whether more closely matching occurrences to timely data will improve your model. Another idea is to pool the data into larger time chunks like we have done in this notebook. This could involve extending our approach of binning the data in 5 year intervals to include occurrence data for 2010-2015, 2005-2009, etc. Either approach would allow you to utilise more of the training data which could greatly assist your SDM training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41413967-761e-46ab-9b2c-310532e8537a",
   "metadata": {},
   "source": [
    "### Addressing bias\n",
    "\n",
    "Below we define some functions to assist in plotting the frog data. This will assist us in identifying two main areas of bias. We then use these functions to plot the frog species distributions of each country. A more detailed exploration of the training dataset for this challenge can be found in the [dataset summary notebook](supplementary_notebooks/dataset_summary.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd4236-b9a9-4622-9a59-2a3365ae9a01",
   "metadata": {},
   "source": [
    "## Predictor Variables\n",
    "\n",
    "Now that we have our response variable, it is time to gather the predictor variables from the TerraClimate dataset. For a more in-depth look at the TerraClimate dataset and how to query it, see the [TerraClimate supplementary notebook](./supplementary_notebooks/TerraClimate.ipynb)\n",
    "\n",
    "### Accessing the TerraClimate Data\n",
    "\n",
    "To get the TerraClimate data, we write a function called `get_terraclimate`. This function will fetch all data intersecting with the bounding box and will calculate various metrics over the time dimension for each coordinate. In this example, we will take four metrics from four assets, namely the mean maximum monthly air temp (`tmax_mean`), mean minimum monthly air temp (`tmin_mean`), mean accumulated precipitation (`ppt_mean`) and mean soil moisture (`soil_mean`), all calculated over a five year timeframe from the start of 2015 to the end of 2019.\n",
    "\n",
    "To assist in visualisations, this function has an interpolation functionality which will allow the comparitively coarse temporal resolution of the terraclimate data to be mapped to a larger set of coordinates, creating an ($n$ x $m$) image. We will choose (512 x 512).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "895f4351-847a-4c66-a764-f9a0888b9869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_terraclimate(bbox, metrics, time_slice=None, assets=None, features=None, interp_dims=None, verbose=True):\n",
    "    \"\"\"Returns terraclimate metrics for a given area, allowing results to be interpolated onto a larger image.\n",
    "    \n",
    "    Attributes:\n",
    "    bbox -- Tuple of (min_lon, min_lat, max_lon, max_lat) to define area\n",
    "    metrics -- Nested dictionary in the form {<metric_name>:{'fn':<metric_function>,'params':<metric_kwargs_dict>}, ... }\n",
    "    time_slice -- Tuple of datetime strings to select data between, e.g. ('2015-01-01','2019-12-31')\n",
    "    assets -- list of terraclimate assets to take\n",
    "    features -- list of asset metrics to take, specified by strings in the form '<asset_name>_<metric_name>'\n",
    "    interp_dims -- Tuple of dimensions (n, m) to interpolate results to\n",
    "    \"\"\"\n",
    "    min_lon, min_lat, max_lon, max_lat = bbox\n",
    "    \n",
    "    collection = pystac.read_file(\"https://planetarycomputer.microsoft.com/api/stac/v1/collections/terraclimate\")\n",
    "    asset = collection.assets[\"zarr-https\"]\n",
    "    store = fsspec.get_mapper(asset.href)\n",
    "    data = xr.open_zarr(store, **asset.extra_fields[\"xarray:open_kwargs\"])\n",
    "    \n",
    "    # Select datapoints that overlap region\n",
    "    if time_slice is not None:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat),time=slice(time_slice[0],time_slice[1]))\n",
    "    else:\n",
    "        data = data.sel(lon=slice(min_lon,max_lon),lat=slice(max_lat,min_lat))\n",
    "    if assets is not None:\n",
    "        data = data[assets]\n",
    "    print('Loading data') if verbose else None\n",
    "    data = data.rename(lat='y', lon='x').to_array().compute()\n",
    "        \n",
    "    # Calculate metrics\n",
    "    combined_values = []\n",
    "    combined_bands = []\n",
    "    for name, metric in metrics.items():\n",
    "        print(f'Calculating {name}') if verbose else None\n",
    "        sum_data = xr.apply_ufunc(\n",
    "            metric['fn'], data, input_core_dims=[[\"time\"]], kwargs=metric['params'], dask = 'allowed', vectorize = True\n",
    "        ).rename(variable='band')\n",
    "        xcoords = sum_data.x\n",
    "        ycoords = sum_data.y\n",
    "        dims = sum_data.dims\n",
    "        combined_values.append(sum_data.values)\n",
    "        for band in sum_data.band.values:\n",
    "            combined_bands.append(band+'_'+name)\n",
    "        \n",
    "    # Combine metrics\n",
    "    combined_values = np.concatenate(\n",
    "        combined_values,\n",
    "        axis=0\n",
    "    )\n",
    "    combined_data = xr.DataArray(\n",
    "        data=combined_values,\n",
    "        dims=dims,\n",
    "        coords=dict(\n",
    "            band=combined_bands,\n",
    "            y=ycoords,\n",
    "            x=xcoords\n",
    "        )\n",
    "    )    \n",
    "\n",
    "    # Take relevant bands:\n",
    "    combined_data = combined_data.sel(band=features)\n",
    "    \n",
    "    if interp_dims is not None:\n",
    "        print(f'Interpolating image') if verbose else None\n",
    "        interp_coords = (np.linspace(bbox[0], bbox[2], interp_dims[0]), np.linspace(bbox[1], bbox[3], interp_dims[1]))\n",
    "        combined_data = combined_data.interp(x=interp_coords[0], y=interp_coords[1], method='nearest', kwargs={\"fill_value\": \"extrapolate\"})\n",
    "    \n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a272993e-7969-48cb-a1b5-4e5e5a99aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxs = [(144.8,-38.5,145.8,-37.5),\n",
    "(150.7,-33.5,151.7,-32.5),\n",
    "(152.6,-29.0,153.6,-28.0),\n",
    "(145.0,-17.7,146.0,-16.7),\n",
    "(115.7,-32.5,116.7,-31.5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e65acf-b700-43a3-9c39-d0f40a87e616",
   "metadata": {},
   "source": [
    "Below, we define the products to take from TerraClimate in `assets` and the metrics to calculate from them in `tc_metrics`. Each metric is applied to each asset, so to pick the desired asset/metric pairs we define a list of strings in the form '\\<asset\\>_\\<metric\\>' in `features`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd7da9ea-10ed-418e-a803-ea4db74e0c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "Calculating mean\n",
      "Calculating min\n",
      "Calculating max\n",
      "Calculating std\n",
      "Interpolating image\n",
      "Loading data\n",
      "Calculating mean\n",
      "Calculating min\n",
      "Calculating max\n",
      "Calculating std\n",
      "Interpolating image\n",
      "Loading data\n",
      "Calculating mean\n",
      "Calculating min\n",
      "Calculating max\n",
      "Calculating std\n",
      "Interpolating image\n",
      "Loading data\n",
      "Calculating mean\n",
      "Calculating min\n",
      "Calculating max\n",
      "Calculating std\n",
      "Interpolating image\n",
      "Loading data\n",
      "Calculating mean\n",
      "Calculating min\n",
      "Calculating max\n",
      "Calculating std\n",
      "Interpolating image\n"
     ]
    }
   ],
   "source": [
    "# Metrics to measure over time dimension\n",
    "tc_metrics = {\n",
    "    'mean':{\n",
    "        'fn':np.mean,\n",
    "        'params':{}\n",
    "    },\n",
    "    'min':{\n",
    "        'fn':np.nanmin,\n",
    "        'params':{}\n",
    "    },\n",
    "    'max':{\n",
    "        'fn':np.nanmax,\n",
    "        'params':{}\n",
    "    },\n",
    "    'std':{\n",
    "        'fn':np.std,\n",
    "        'params':{}\n",
    "    },\n",
    "}\n",
    "\n",
    "# Date range to take\n",
    "time_slice = ('2015-01-01','2019-12-31')\n",
    "\n",
    "# Measurements to take\n",
    "assets=['tmax', 'tmin', 'ppt', 'soil']\n",
    "\n",
    "# Features to take, in form '<asset>_<metric>'\n",
    "features=['tmax_min',\n",
    "          'tmax_max',\n",
    "          'tmax_mean',\n",
    "          'tmin_max',\n",
    "          'tmin_mean',\n",
    "          'ppt_mean',\n",
    "          'ppt_std', \n",
    "          'soil_mean',\n",
    "         'soil_max']\n",
    "\n",
    "# Interpolate values to a 512x512 image\n",
    "interp_dims = (512, 512)\n",
    "\n",
    "# Load in data\n",
    "\n",
    "arrays=[]\n",
    "for bbox in bboxs:\n",
    "    weather_data = get_terraclimate(bbox, tc_metrics, time_slice=time_slice, assets=assets, features=features, interp_dims=interp_dims)\n",
    "    arrays.append(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d1811e-247b-4cc0-a217-0720e0c0ac43",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../training_data/occurrence.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4696/3958777790.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfrogs_all_bboxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mbbox\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbboxs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mall_frog_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_frogs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/training_data/occurrence.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2015\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2019\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mfrogs_all_bboxs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_frog_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4696/2808823280.py\u001b[0m in \u001b[0;36mget_frogs\u001b[1;34m(file, year_range, bbox)\u001b[0m\n\u001b[0;32m     32\u001b[0m     }\n\u001b[0;32m     33\u001b[0m     frogs = (\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'training_data/occurrence.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'eventDate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         .assign(\n\u001b[0;32m     36\u001b[0m             \u001b[0mcountry\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcountryCode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcountry_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\2022DSC\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../training_data/occurrence.txt'"
     ]
    }
   ],
   "source": [
    "frogs_all_bboxs = []\n",
    "for bbox in bboxs:\n",
    "    all_frog_data = get_frogs(data_path+'/training_data/occurrence.txt', year_range=(2015, 2019), bbox=bbox)\n",
    "    frogs_all_bboxs.append(all_frog_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca82858-9fc3-4b1c-83d2-43015387c6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_species = 'Litoria Fallax'\n",
    "for all_frog_data in frogs_all_bboxs:\n",
    "\n",
    "    all_frog_data = (\n",
    "        all_frog_data\n",
    "        # Assign the occurrenceStatus to 1 for the target species and 0 for all other species.\n",
    "        # as well as a key for joining (later)\n",
    "        .assign(\n",
    "            occurrenceStatus = lambda x: np.where(x.species == target_species, 1, 0)\n",
    "        )\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81304887-d910-4dc1-8bbe-5eeb851d6c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_species = 'Litoria Fallax'\n",
    "for i in range(len(frogs_all_bboxs)):\n",
    "    frogs_all_bboxs[i] = (\n",
    "        frogs_all_bboxs[i]\n",
    "        # Assign the occurrenceStatus to 1 for the target species and 0 for all other species.\n",
    "        # as well as a key for joining (later)\n",
    "        .assign(\n",
    "            occurrenceStatus = lambda x: np.where(x.species == target_species, 1, 0)\n",
    "        )\n",
    "        .assign(key=lambda x: x.index)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7661c339-191f-4979-9c60-f7250e06cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(frogs_all_bboxs)):\n",
    "    print(i, frogs_all_bboxs[i]['occurrenceStatus'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f0545f-1f4f-465e-99aa-debd26094596",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(frogs_all_bboxs)):\n",
    "    print(frogs_all_bboxs[i][\"species\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cc3ce-567f-405f-9c5e-acc69c136a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_frogs = pd.concat(frogs_all_bboxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a747a2d6-0a80-4b4a-b12c-9ea75810d805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4099ca2a-59e3-4cef-b14f-e9f5ce160b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_frogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e78a134-e4ad-4375-af8c-37e1d5aba7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_frogs[\"species\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256670ce-1b1b-4f05-9503-afb78581a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aadd0c2-79c4-45e7-be20-ef473de70adf",
   "metadata": {},
   "source": [
    "# Options for downsampling frogs\n",
    "1. leave it as is, no downsampling\n",
    "1. take out randomly to make target match non-target\n",
    "1. take out randomly to make each species equal\n",
    "1. take out systmatically trying to leave frogs evenly distributed. eg, take out nearest neighbors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22506e4e-596c-4181-8e69-039dc9b675a3",
   "metadata": {},
   "source": [
    "## HERE I choose option 2, take out rnadomy to make number of target frogs == number of non-target frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c46b7c-5a21-4311-bd0c-265eae7e7a03",
   "metadata": {},
   "source": [
    "### Visualising the TerraClimate Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7a3347-a22d-4369-ae28-131326f72bc5",
   "metadata": {},
   "source": [
    "The spatial distribution of the four variables are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022d8700-710d-4f39-8d7f-661fd29f583b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 2\n",
    "for j in range(len(arrays)):\n",
    "    fig, ax = plt.subplots(nrow, ncol, figsize=(13, 7), sharex=True, sharey=True)\n",
    "\n",
    "    bands = arrays[j].band.values\n",
    "    #filt = frog_data.occurrenceStatus == 1\n",
    "    cmaps = [\"cool\", \"cool\", \"Blues\", \"BrBG\"]\n",
    "\n",
    "    for i in range(len(bands)):\n",
    "        xr.plot.imshow(arrays[j][i], 'x', 'y', cmap=cmaps[i], ax=ax[i//ncol, i%ncol]) \n",
    "        ax[i//ncol, i%ncol].set_title(bands[i])\n",
    "        #ax[i//ncol, i%ncol].scatter(frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude,\n",
    "        #                            color = 'yellow', marker='.', alpha=0.5, label=target_species if i==0 else '')\n",
    "\n",
    "    fig.suptitle(\"Spatial distribution of Terraclimate variables\", fontsize=20)\n",
    "    fig.legend(loc=(0.85, 0.933))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d978818a-a975-4d14-a799-c7327073ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxs[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b4e3c2-3971-4f04-9ca7-19e059948517",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd00439-c77f-4aaf-9cf7-274457de8b2d",
   "metadata": {},
   "source": [
    "The frequency distribution of each variable is displayed below. There is some skewness present in a few variables, so you might want to address this when training your own model. Depending on the type of model you decide to train, some of the variables might require normalisation, standardisation, or transformation. For now, we will proceed with the variables as they come."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4e9aaf-6b2c-4587-8b32-64e739591615",
   "metadata": {},
   "outputs": [],
   "source": [
    "nrow = 2\n",
    "ncol = 2\n",
    "fig, ax = plt.subplots(nrow, ncol, figsize=(13, 7))\n",
    "\n",
    "bands = weather_data.band.values\n",
    "\n",
    "for i in range(len(bands)):\n",
    "    xr.plot.hist(weather_data[i], ax=ax[i//ncol, i%ncol])\n",
    "\n",
    "fig.suptitle(\"Frequency distribution of TerraClimate variables\",  fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0774bc5-4dff-4812-a1c6-70768abca0c9",
   "metadata": {},
   "source": [
    "### Joining Pretictors to the Response Variable\n",
    "\n",
    "Now that we have read in our predictor variables, we need to join them onto the response variable of frogs. To do this, we loop through the frog occurrence data and assign each frog occurrence the closest predictor pixel value from each of the predictor variables based on the geo-coordinates. The `sel` method of the xarray dataarray comes in handy here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397daf8-cb09-4a57-8317-e3a7d13a2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_frogs(frog_data, data):\n",
    "    \"\"\"Collects the data for each frog location and joins it onto the frog data \n",
    "\n",
    "    Arguments:\n",
    "    frogs -- dataframe containing the response variable along with [\"decimalLongitude\", \"decimalLatitude\", \"key\"]\n",
    "    data -- xarray dataarray of features, indexed with geocoordinates\n",
    "    \"\"\"\n",
    "    return frog_data.merge(\n",
    "        (\n",
    "            data\n",
    "            .rename('data')\n",
    "            .sel(\n",
    "                x=xr.DataArray(frog_data.decimalLongitude, dims=\"key\", coords={\"key\": frog_data.key}), \n",
    "                y=xr.DataArray(frog_data.decimalLatitude, dims=\"key\", coords={\"key\": frog_data.key}),\n",
    "                method=\"nearest\"\n",
    "            )\n",
    "            .to_dataframe()\n",
    "            .assign(val = lambda x: x.iloc[:, -1])\n",
    "            [['val']]\n",
    "            .reset_index()\n",
    "            .drop_duplicates()\n",
    "            .pivot(index=\"key\", columns=\"band\", values=\"val\")\n",
    "            .reset_index()\n",
    "        ),\n",
    "        on = ['key'],\n",
    "        how = 'inner'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4b53f7-ef64-40b7-8572-ba9de56932d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = []\n",
    "for i in range(len(frogs_all_bboxs)):\n",
    "    model_data = join_frogs(frogs_all_bboxs[i], arrays[i])\n",
    "    all_pairs.append(model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf7ef4b-56ad-4e1f-9505-d656a6686ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = pd.concat(all_pairs)\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef70ab7-0bce-4d9d-a5e4-137041c55108",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_species_frog_data = model_data[model_data.occurrenceStatus == 1]\n",
    "frog_data = (\n",
    "    model_data\n",
    "    [lambda x: x.occurrenceStatus == 0]\n",
    "    .sample(\n",
    "        len(target_species_frog_data), random_state=420\n",
    "    )\n",
    "    .append(target_species_frog_data)\n",
    "    # assign key for joining purposes\n",
    "    .reset_index(drop=True)\n",
    "    .assign(key=lambda x: x.index)\n",
    ")\n",
    "model_data = frog_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2acdc-8f12-44c3-a751-cd1622be79ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb154fe-e72c-4e0f-b4ea-5a20384de3f5",
   "metadata": {},
   "source": [
    "## Model Building\n",
    "\n",
    "### Model Training\n",
    "\n",
    "Now that we have the data in a format appropriate for machine learning, we can begin training a model. For this demonstration notebook, we will use a basic logistic regression model from the [scikit-learn](https://scikit-learn.org/stable/) library. This library offers a wide range of other models, each with the capacity for extensive parameter tuning and customisation capabilities.\n",
    "\n",
    "Scikit-learn models require separation of predictor variables and the response variable. We store the predictor variables in dataframe `X` and the response in the array `y`. We must make sure to drop the response variable from `X`, otherwise the model will have the answers! It also doesn't make sense to use latitude and longitude as predictor variables in such a confined area, so we drop those too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f37bbf2-2764-4e73-9cdd-aed143fb61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b69df75-08a7-49a7-aa43-2c4512436156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_model = LogisticRegression()\n",
    "model_data_noNans = model_data.dropna()\n",
    "\n",
    "X = (\n",
    "    model_data_noNans\n",
    "    .drop(['gbifID', 'eventDate', 'decimalLatitude', 'decimalLongitude', 'species',\n",
    "       'country', 'continent', 'stateProvince', 'occurrenceStatus', 'key'], 1)\n",
    ")\n",
    "y = model_data_noNans.occurrenceStatus.astype(int)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "y=y.reset_index(drop=True)\n",
    "X_scaled = scaler.transform(X)\n",
    "X_scaled_labeled = pd.DataFrame(X_scaled)\n",
    "X_scaled_labeled = X_scaled_labeled.set_axis(X.columns, axis='columns')\n",
    "#full_model.fit(X_scaled_labeled, y)\n",
    "clf_no_DS = MLPClassifier().fit(X_scaled_labeled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565957c9-cba5-4948-84b6-c8f74f4cf598",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "\n",
    "#### Predict Training Set\n",
    "\n",
    "Logistic regression is a machine learning model that estimates the probability of a binary response variable. In our case, the model will output the probability of a frog being present at a given location. To obtain the predictions for our training set, we simply use the `predict` method on our trained model. We will evaluate these predictions in the evaluation section of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08498c-42ae-4e06-9f15-f5d6d218b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_test = pd.concat(all_pairs)\n",
    "model_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df97e8ec-0e55-487b-a0b9-ebbba733ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_test_noNans = model_data_test.dropna()\n",
    "\n",
    "X_test = (\n",
    "    model_data_test_noNans\n",
    "    .drop(['gbifID', 'eventDate', 'decimalLatitude', 'decimalLongitude', 'species',\n",
    "       'country', 'continent', 'stateProvince', 'occurrenceStatus', 'key'], 1)\n",
    ")\n",
    "y_test = model_data_test_noNans.occurrenceStatus.astype(int)\n",
    "\n",
    "y_test=y_test.reset_index(drop=True)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_test_scaled_labeled = pd.DataFrame(X_test_scaled)\n",
    "X_test_scaled_labeled = X_test_scaled_labeled.set_axis(X_test.columns, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b014512-659b-4f72-9102-b2b31c51bd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions = full_model.predict(X)\n",
    "predictions = clf_no_DS.predict(X_test_scaled_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97af275-bdc3-4653-ad3d-8da1481965d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c11356-c8a2-4579-acf5-d649db5a5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test_scaled_labeled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d284737c-ca49-4272-9935-62e582e6cb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test_scaled_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823ca0f-107d-4ab7-ad56-eb359762b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_names_in_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51835e-6061-4db0-9ad1-3a2510c6b271",
   "metadata": {},
   "source": [
    "#### Predict Entire Region\n",
    "\n",
    "For a species distribution model to be effective, it must also be capable of performing predictions over the entire region, not just the points in our training set. To do this, we will define another function called `predict_frogs` that will take our interpolated predictor variable image in, along with our logistic regression model, and output the probabilities for each pixel in the region. We will visualise these predictions in a heatmap in the results section of this notebook.\n",
    "\n",
    "This function will be used later to predict the test regions for the challenge. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a306561-6f2b-4f0d-9ede-b98b702ac226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_frogs(predictor_image, model):\n",
    "    \"\"\"Returns a (1, n, m) xarray where each pixel value corresponds to the probability of a frog occurrence.\n",
    "    \n",
    "    Takes in the multi-band image outputted by the `create_predictor_image` function as well as the\n",
    "    trained model and returns the predictions for each pixel value. Firstly, the $x$ and $y$ indexes\n",
    "    in the predictor image are stacked into one multi-index $z=(x, y)$ to produce an $k\\times n$\n",
    "    array, which is the format required to feed into our logistic regression model. Then, the array\n",
    "    is fed into the model, returning the model's predictions for the frog likelihood at each pixel. \n",
    "    The predicted probabilities are then indexed by the same multi-index $z$ as before, which allows \n",
    "    the array to be unstacked and returned as a one-band image, ready for plotting.\n",
    "\n",
    "    Arguments:\n",
    "    predictor_image -- (K, n, m) xarray, where K is the number of predictor variables.\n",
    "    model -- sklearn model with K predictor variables.\n",
    "    \"\"\"\n",
    "    # Stack up pixels so they are in the appropriate format for the model\n",
    "    predictor_image = predictor_image.stack(z=(\"y\", \"x\")).transpose()\n",
    "    # Reorder variables to be in same order as model\n",
    "    predictor_image = predictor_image.sel(band=model.feature_names_in_)\n",
    "    ## preform preprocessing ###\n",
    "    scaled_data = scaler.transform(predictor_image.data)\n",
    "    predictor_image.data = scaled_data\n",
    "    ### end preprocessing ###\n",
    "    \n",
    "    # Location of null values so that we can skip them (prediction model will break if nulls are present)\n",
    "    null_pixels = (np.sum(predictor_image.isnull(), axis=-1) > 0)\n",
    "    # Empty probabilities array\n",
    "    probabilities = np.zeros((len(null_pixels), 2))\n",
    "    # Calculate probability for each non-null pixel point\n",
    "    probabilities[~null_pixels] = model.predict_proba(\n",
    "        predictor_image[~null_pixels]\n",
    "    )\n",
    "    # Set null pixels to a probability of null\n",
    "    probabilities[null_pixels] = np.array([np.nan, np.nan])\n",
    "    # Just take probability of frog (class=1)\n",
    "    probabilities = probabilities[:,1]\n",
    "    # Add the coordinates to the probabilities, saving them in an xarray\n",
    "    resultant_image = xr.DataArray(\n",
    "        data=probabilities,\n",
    "        dims=['z'],\n",
    "        coords=dict(\n",
    "            z=predictor_image.z\n",
    "        )\n",
    "    )\n",
    "    # Unstack the image\n",
    "    resultant_image = resultant_image.unstack()\n",
    "    return resultant_image\n",
    "\n",
    "# Calculate probability for each pixel point \n",
    "resultant_image = predict_frogs(weather_data, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca09d5-b7d1-42cf-80cb-66fc23225974",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "\n",
    "Now that we have trained our model and made some predictions, all that is left is to evaluate it. We will do this by first visualising the output of the model with a probability heatmap. Then, we will evaluate both its in-sample and out-of-sample performance using the training set we have generated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08badfa5-98bd-4962-b39a-a19966babfd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### In-Sample Evaluation\n",
    "\n",
    "In the last section, we made our predicitons for the training set and stored them in the `predictions` variable. We can now calculate some performance metrics to guage the effectiveness of the model. It must be stressed that this is the in-sample performance - the performance on the training set. Hence, the values will tend to overestimate its performance. Additionally, the training set itself is biased and this notebook only took naive approaches to address this. The model evaluation metrics are only as good as the data used to evaluate it, so the metrics themselves will also be biased. Thus, these metrics are NOT truly indicative of this model's performance. \n",
    "\n",
    "In this example, we will use `f1_score` and `accuracy_score` from Scikit-learn. Scikit-learn provides many other metrics that can be used for evaluation. You can even code your own if you think it will assist you in evaluating your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45db621c-d83f-4ffc-ba7e-8579a79da9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"F1 Score: {np.mean(f1_score(y_test, predictions)).round(2)}\")\n",
    "print(f\"Accuracy: {np.mean(accuracy_score(y_test, predictions)).round(2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540e3712-5c71-4844-9a28-b133623d3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in [0.5, 0.6, 0.7, 0.8]:\n",
    "    pred = (clf.predict_proba(X_test_scaled_labeled)[:,1] > thresh)\n",
    "    print(str(thresh))\n",
    "    print(f\"F1 Score: {np.mean(f1_score(y_test, pred)).round(4)}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy_score(y_test, pred)).round(4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb8273-0abd-4b00-a3a6-5b903e292176",
   "metadata": {},
   "outputs": [],
   "source": [
    "for thresh in [0.5, 0.55, 0.6]:\n",
    "    pred = (clf.predict_proba(X_test_scaled_labeled)[:,1] > thresh)\n",
    "    print(str(thresh))\n",
    "    print(f\"F1 Score: {np.mean(f1_score(y_test, pred)).round(4)}\")\n",
    "    print(f\"Accuracy: {np.mean(accuracy_score(y_test, pred)).round(4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3a0a1-52a9-4854-8491-3499323a898f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5000c45-17be-4d7f-969f-3b73900967fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d98b45-b950-4041-929f-8d0ffa193367",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e96a35-f916-4b63-9d73-640ce102b3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict_proba(X_test_scaled_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc233a65-8f73-4dd2-9748-b398caf6f297",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions == (clf.predict_proba(X_test_scaled_labeled)[:,1] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ea862-0e9f-469f-8d18-f790cd738304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_estimator(clf, X_test_scaled_labeled, y_test, display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Model Level 1: Logistic\\nRegression Model In-Sample Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47abbe6d-665d-4469-9c33-3eeb623159d4",
   "metadata": {},
   "source": [
    "From above, we see that the model is able to achieve an ok F1 score and accuracy. From the confusion matrix, we can see that our model seems to confuse absent points with present points aka false positives, as shown in the top right corner. There may be many reasons for this, and a great way of understanding what might be causing the model's high false positive rate is to visualise its performance over the training region. We do this by plotting a probabilty heatmap in the section below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c1c74-e309-4fb5-9063-e680651f3bc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Probability Heatmap\n",
    "\n",
    "To create the probability heatmap, we write a function called `plot_heatmap`. This function will take in the model predictions from the entire region as stored in the `resultant_image` variable, and visualise these probabilities as a heatmap. In addition to the heatmap, we will also plot the actual map of the area in question, and the binary classification regions of the probability heatmap. The latter is simply a binary mask of the probability heatmap, 1 where the probability is greater than 0.5 and 0 elsewhere. \n",
    "\n",
    "To help visualise the effectiveness of our model, we plot the target species occurrences over top of each image. This can give us an idea of where our model is doing well, and where it is doing poorly. Particularly, we are interested in the high false positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afb12b7-395d-4741-8ed6-0487f6d611d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap(resultant_image, frog_data, title, crs = {'init':'epsg:4326'}):\n",
    "    \"\"\"Plots a real map, probability heatmap, and model classification regions for the probability image from our model.\n",
    "\n",
    "    Arguments:\n",
    "    resultant_image -- (1, n, m) xarray of probabilities output from the model\n",
    "    frog_data -- Dataframe of frog occurrences, indicated with a 1 in the occurrenceStatus column. \n",
    "                 Must contain [\"occurrenceStatus\", \"decimalLongitude\", \"decimalLatitude\"]\n",
    "    title -- string that will be displayed as the figure title\n",
    "    crs -- coordinate reference system for plotting the real map. Defaults to EPSG:4326.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (20, 10), sharex=True, sharey=True)\n",
    "    extent = [resultant_image.x.min(),resultant_image.x.max(),resultant_image.y.min(),resultant_image.y.max()]\n",
    "    cmap = 'PiYG'\n",
    "\n",
    "    # Plot real map\n",
    "    ax[0].scatter(x=[extent[0], extent[1]], y=[extent[2], extent[3]], alpha=0)\n",
    "    cx.add_basemap(ax[0], crs=crs)\n",
    "    ax[0].set_title('Real map')\n",
    "    \n",
    "    # Plot heatmap from model\n",
    "    heatmap = resultant_image.plot.imshow(\n",
    "        x='x', y='y', ax=ax[1], cmap=cmap, vmin=0, vmax=1, interpolation='none', add_colorbar=False\n",
    "    )\n",
    "    ax[1].set_aspect('equal')\n",
    "    ax[1].set_title('Model Probability Heatmap')\n",
    "\n",
    "    # Plot binary classification from model\n",
    "    regions = xr.where(resultant_image.isnull(), np.nan, resultant_image>0.5).plot.imshow(\n",
    "            x='x', y='y', ax=ax[2], cmap=cmap, vmin=0, vmax=1, interpolation='none', add_colorbar=False\n",
    "    )\n",
    "    ax[2].set_aspect('equal')\n",
    "    ax[2].set_title('Model Classification Regions')\n",
    "\n",
    "    # Plot real frogs\n",
    "    for i, axis in enumerate(ax):\n",
    "        filt = frog_data.occurrenceStatus == 1\n",
    "        axis.scatter(\n",
    "            frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, \n",
    "            color = 'dodgerblue', marker='.', alpha=0.5, label='Target Species' if i==0 else ''\n",
    "        )\n",
    "        non_target = frog_data.occurrenceStatus == 0\n",
    "        axis.scatter(\n",
    "            frog_data[non_target].decimalLongitude, frog_data[non_target].decimalLatitude, \n",
    "            color = 'yellow', marker='.', alpha=0.5, label='Off-Target Species' if i==0 else ''\n",
    "        )\n",
    "    fig.colorbar(heatmap, ax=ax, location = 'bottom', aspect=40)\n",
    "    fig.legend(loc = (0.9, 0.9))\n",
    "    fig.suptitle(title, x=0.5, y=0.9, fontsize=20)\n",
    "    \n",
    "#plot_heatmap(resultant_image, all_all_frogs, f\"Logistic Regression Model Results - {region_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1e829d-886b-415f-a701-f0ee63bca664",
   "metadata": {},
   "outputs": [],
   "source": [
    "for weather_data in arrays:\n",
    "    plot_heatmap(predict_frogs(weather_data, clf), all_all_frogs, f\"Logistic Regression Model Results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab57d7-29c2-4cf9-b6cf-644ff6504a7d",
   "metadata": {},
   "source": [
    "From the plots above, we can see that the model does a pretty good job of mapping where litoria fallax is. However, our performance metrics before suggested otherwise. The main limitation of the evaluation metrics comes from the pseudo absence species, crinia signifera, sharing much of the same habitat as litoria fallax. This paired with the relatively coarse spatial resolution of TerraClimate makes distinguising close habitats difficult. This explains the high rate of false positives, as there are many frog absence points within the green classification region. \n",
    "\n",
    "There are many ways you might go about addressing this issue. Perhaps choosing a species that does not closely share the same habitat as litoria fallax. Alternatively, a greater variety of spatial sampling could also resolve this issue, i.e. picking extra regions where only litoria fallax exists and some where only other species exist. Another option is to abandon the pseudo-absence approach entirely and develop a unique way of sampling for absence points. Ultimately, you might think it is worthwhile improving the training set to make your evaluation metrics a little more representative of the SDM performance. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81cb71d-5bb0-4a1a-aa5f-e20cfb7a560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmap_w_thresh(resultant_image, frog_data, title, thresholds, crs = {'init':'epsg:4326'}):\n",
    "    \"\"\"Plots a real map, probability heatmap, and model classification regions for the probability image from our model.\n",
    "\n",
    "    Arguments:\n",
    "    resultant_image -- (1, n, m) xarray of probabilities output from the model\n",
    "    frog_data -- Dataframe of frog occurrences, indicated with a 1 in the occurrenceStatus column. \n",
    "                 Must contain [\"occurrenceStatus\", \"decimalLongitude\", \"decimalLatitude\"]\n",
    "    title -- string that will be displayed as the figure title\n",
    "    crs -- coordinate reference system for plotting the real map. Defaults to EPSG:4326.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (20, 10), sharex=True, sharey=True)\n",
    "    extent = [resultant_image.x.min(),resultant_image.x.max(),resultant_image.y.min(),resultant_image.y.max()]\n",
    "    cmap = 'PiYG'\n",
    "\n",
    "    # Plot real map\n",
    "    for i, threshold in enumerate(thresholds):\n",
    "        ax[i].scatter(x=[extent[0], extent[1]], y=[extent[2], extent[3]], alpha=0)\n",
    "        cx.add_basemap(ax[i], crs=crs)\n",
    "        regions = xr.where(resultant_image.isnull(), np.nan, resultant_image>threshold).plot.imshow(\n",
    "            x='x', y='y', ax=ax[i], cmap=cmap, vmin=0, vmax=1, interpolation='none', add_colorbar=False\n",
    "    )\n",
    "        ax[i].set_aspect('equal')\n",
    "        ax[i].set_title('Model Classification Regions')\n",
    "\n",
    "    # Plot binary classification from model\n",
    "\n",
    "\n",
    "    # Plot real frogs\n",
    "    for i, axis in enumerate(ax):\n",
    "        filt = frog_data.occurrenceStatus == 1\n",
    "        axis.scatter(\n",
    "            frog_data[filt].decimalLongitude, frog_data[filt].decimalLatitude, \n",
    "            color = 'dodgerblue', marker='.', alpha=0.5, label='Target Species' if i==0 else ''\n",
    "        )\n",
    "        non_target = frog_data.occurrenceStatus == 0\n",
    "        axis.scatter(\n",
    "            frog_data[non_target].decimalLongitude, frog_data[non_target].decimalLatitude, \n",
    "            color = 'yellow', marker='.', alpha=0.5, label='Off-Target Species' if i==0 else ''\n",
    "        )\n",
    "    #fig.colorbar(heatmap, ax=ax, location = 'bottom', aspect=40)\n",
    "    fig.legend(loc = (0.9, 0.9))\n",
    "    fig.suptitle(title, x=0.5, y=0.9, fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15d317d-44c5-47f7-b664-967dc0b21535",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.7, 0.9]\n",
    "for weather_data in arrays[1:4]:\n",
    "    plot_heatmap_w_thresh(predict_frogs(weather_data, clf), all_all_frogs, f\"Logistic Regression Model Results\",thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877a2893-d21e-469b-9b44-1b4466682fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0.5, 0.6, 0.7]\n",
    "for weather_data in arrays[1:4]:\n",
    "    plot_heatmap_w_thresh(predict_frogs(weather_data, clf), all_all_frogs, f\"Logistic Regression Model Results\",thresholds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d77515-bbdc-48aa-b21f-5dd6aff7a52c",
   "metadata": {},
   "source": [
    "#### Out-of-Sample Evaluation\n",
    "\n",
    "When evaluating a machine learning model, it is essential to correctly and fairly evaluate the model's ability to generalise. This is because models have a tendancy to overfit the dataset they are trained on. To estimate the out-of-sample performance, we will use k-fold cross-validation. This technique involves splitting the training dataset into folds, in this case we will use 10. Each iteration, the model is trained on all but one of the folds, which is reserved for testing. This is repeated until all folds have been left out once. At the end of the process, we will have 10 metrics which can be averaged, giving a more reliable and valid measure of model performance. \n",
    "\n",
    "Scikit-learn has built-in functions that can assist in k-fold cross validation. In particular, we will use `StratifiedKFold` to split our data into folds, ensuring there is always a balanced number of frogs and non-frogs in each fold.\n",
    "\n",
    "Again, these metrics are derived from a biased sample, so be careful what you infer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41e992d-08cd-4ce6-9330-852263bd0b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_model = LogisticRegression()\n",
    "\n",
    "n_folds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_folds, random_state=420, shuffle=True)\n",
    "metrics = {'F1': f1_score, 'Accuracy': accuracy_score}\n",
    "results = {'predicted':[], 'actual':[]}\n",
    "scores = {'F1': [], 'Accuracy': []}\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    # Split the dataset\n",
    "    print(f\"Fold {i+1} of {n_folds}\")\n",
    "    X_train, X_test = X.loc[train_index], X.loc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit the model with the training set\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    \n",
    "    predictions = cv_model.predict(X_test)\n",
    "    \n",
    "    for metric, fn in metrics.items():\n",
    "        scores[metric].append(fn(y_test, predictions))\n",
    "        \n",
    "    results['predicted'].extend(predictions)\n",
    "    results['actual'].extend(list(y_test))\n",
    "        \n",
    "print(f'\\nMetrics averaged over {n_folds} trials:')\n",
    "for metric, result in scores.items():\n",
    "    print(f\"{metric}: {np.mean(result).round(2)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d239a36d-4d40-4ce8-ace4-ccad12bc0924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the results in a confusion matrix\n",
    "disp = ConfusionMatrixDisplay.from_predictions(results['actual'], results['predicted'], display_labels=['Absent', 'Present'], cmap='Blues')\n",
    "disp.figure_.set_size_inches((7, 7))\n",
    "disp.ax_.set_title('Model Level 1: Logistic Regression Model\\n10-fold Cross Validation Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cddcdfe-309f-43e5-862a-24497d12450e",
   "metadata": {},
   "source": [
    "The results from the 10-fold cross validation are similar than the in-sample metrics. This is a good sign as it shows that we haven't overfit our model. We see similar behavour in the higher rate of false positives that we saw in the in-sample performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca134a4-7445-4097-ad62-574453c00c21",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "Once you are happy with your model, there will come a time to make a submission to the challenge. To make a submission, you will need to use your model to make predictions about the presence of litoria fallax for a set of test coordinates we have provided. The coordinates are found in the 'challenge_1_submission_template.csv' file, and the list of bounding boxes where the points were sampled from can be found separately in the 'challenge_1_test_regions.txt' file. We recommend looping through the regions identified in that file, pulling the TerraClimate data for that region, and extracting the features for each point in the 'test_1_occurrences.csv' file within that regions bounding box. This will minimise the computational requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acebfca-8e59-4fbb-b87e-9c61406d9310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in test coordinates\n",
    "test_file = pd.read_csv('challenge_1_submission_template.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f923285-32ad-4dfb-8595-1c80e3aebf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in test regions\n",
    "test_1_regions = []\n",
    "with open('challenge_1_test_regions.txt', 'r') as file: \n",
    "    for i, line in enumerate(file):\n",
    "        if i > 0:\n",
    "            test_1_regions.append(eval(\"(\"+line+\")\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856dd01f-4802-44d8-bd30-7ca18aa51cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in regions and save as list of dictionaries.\n",
    "test_regions = [{'title':i, 'bbox':bbox} for i, bbox in enumerate(test_1_regions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909537b-fc16-40d5-bd2e-213e47826091",
   "metadata": {},
   "source": [
    "Note: with the TerraClimate parameters we have set, some areas of each region contain nulls. If this is the case, the prediction will return a null, which evaluates to false when we create the binary mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297c645d-9cf7-4aaa-a93f-a3d1f16fda96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictor data for each region and get predictor image\n",
    "for region in test_regions:\n",
    "    region['coords'] = filter_bbox(test_file[['id', 'decimalLongitude', 'decimalLatitude']], region['bbox'])\n",
    "    region['predictors'] = get_terraclimate(region['bbox'], tc_metrics, time_slice=time_slice, assets=assets, features=features)\n",
    "    region['result'] = predict_frogs(region['predictors'], clf) > 0.5\n",
    "    \n",
    "    region['result'].plot.imshow(x='x', y='y', vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6163446-c903-40af-9e5c-54341203c31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X_test_scaled_labeled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bec83a-6b6b-40b9-b869-87dce4275b80",
   "metadata": {},
   "source": [
    "We can now use these classification regions to assign predictions for each of the coordinates specified in the test file. We do this in a similar way to the `join_frogs` function we defined earlier, except in this case we are joining a prediction to each coordinate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe031cf-400d-40e8-adc1-d2df9e8b4ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame()\n",
    "\n",
    "for region in test_regions:\n",
    "    preds = (\n",
    "        region['result'].rename('occurrenceStatus')\n",
    "        .sel(\n",
    "            x=xr.DataArray(region['coords'].decimalLongitude, dims=\"id\", coords={\"id\": region['coords'].id}), \n",
    "            y=xr.DataArray(region['coords'].decimalLatitude, dims=\"id\", coords={\"id\": region['coords'].id}),\n",
    "            method=\"nearest\"\n",
    "        )\n",
    "        .to_dataframe()\n",
    "        .reset_index()\n",
    "        .rename(columns={'x':'decimalLongitude', 'y':'decimalLatitude'})\n",
    "    )\n",
    "    predictions = predictions.append(preds)\n",
    "            \n",
    "submission = (    \n",
    "    predictions.merge(\n",
    "        test_file, \n",
    "        on=['decimalLongitude', 'decimalLatitude'], \n",
    "        how='left', suffixes = ('', '_'))\n",
    "    [test_file.columns]\n",
    "    .fillna(0)\n",
    "    .astype({col:'int' for col in test_file.columns[3::]})\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b624948-932e-4b06-a23b-72a13767a705",
   "metadata": {},
   "source": [
    "What we are left with is a submission file with three columns: decimalLatitude, decimalLongitude, and occurrenceStatus. This is the file you will submit to the EY Data Science Challenge platform to receive your score on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f60ccee-1fa5-4b35-a6c8-069d9cea33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(submission)\n",
    "\n",
    "# Save to output folder\n",
    "submission.to_csv('all_BB_downsampling_1_robs_metrics_CLF.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39365f50-661f-4af8-aa2f-bd48d744279f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_all_frogs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41938b59-c2be-454e-be3a-80251330aa62",
   "metadata": {},
   "source": [
    "### Get Frogging!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ec962f-89f9-465e-9269-73374840dcb8",
   "metadata": {},
   "source": [
    "Now that you have witnessed a basic approach to model training, its time to try your own approach! Feel free to modify any of the functions presented in this notebook. A good start might be to try running this notebook on a region different to Greater Sydney, or even on multiple regions.\n",
    "\n",
    "Be sure to address some of the assumptions made here, particularly ways to address the sampling bias in the dataset. Our pseudo-absence method was just one idea, you may want to persue another. Another important issue to consider is that of class imbalance. In this notebook, we simply down-sampled the non-target species to match the number of target species. This may not be ideal, as an isolated frog occurrence may be lost while clusters of occurrences are more likely to persist. Perhaps a method of sampling only from clustered occurrences would address class imbalance while also helping to offset the sampling bias. Just a thought! You might even decide on a completely different training set, such as classifying regions rather than points. Do whatever you think will create the best model for predicting the frog habitat of the species of interest. Happy frogging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3be98d-be06-44b2-b459-33cde907f64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictor data for each region and get predictor image\n",
    "for region in test_regions:\n",
    "    region['coords'] = filter_bbox(test_file[['id', 'decimalLongitude', 'decimalLatitude']], region['bbox'])\n",
    "    region['predictors'] = get_terraclimate(region['bbox'], tc_metrics, time_slice=time_slice, assets=assets, features=features)\n",
    "    ### modification to add noise #### \n",
    "    added_bands = ['noisey']\n",
    "    originial_data = region['predictors']\n",
    "    \n",
    "    dims = originial_data.dims\n",
    "    ycoords = originial_data.y\n",
    "    xcoords = originial_data.x\n",
    "    combined_bands = list(originial_data.band.values)\n",
    "\n",
    "    for i in range(len(added_bands)):\n",
    "        combined_bands.append(added_bands[i])\n",
    "    combined_bands = np.array(combined_bands)\n",
    "    originial_band_number = originial_data.values.shape[0]\n",
    "    originial_data_band_shape =originial_data.values.shape[1:]\n",
    "    new_values = np.zeros([originial_band_number+len(added_bands), originial_data.values.shape[1], originial_data.values.shape[2]])\n",
    "    new_values[0:originial_band_number] = originial_data.values\n",
    "    new_values[originial_band_number:originial_band_number+len(added_bands)] = np.random.randn(*originial_data_band_shape)*100\n",
    "    \n",
    "    modified_data = xr.DataArray(\n",
    "    data=new_values,\n",
    "    dims=dims,\n",
    "    coords=dict(\n",
    "        band=combined_bands,\n",
    "        y=ycoords,\n",
    "        x=xcoords)\n",
    "    )\n",
    "    \n",
    "    region['result'] = predict_frogs(modified_data, full_model) > 0.5\n",
    "    ### modification to add noise ### \n",
    "    region['result'].plot.imshow(x='x', y='y', vmin=0, vmax=1)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:2022DSC] *",
   "language": "python",
   "name": "conda-env-2022DSC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
